{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2S-uFqwSvmg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUxLkBjISvmr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.76, NNZs: 15, Bias: -0.314605, T: 37500, Avg. loss: 0.455801\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.92, NNZs: 15, Bias: -0.469578, T: 75000, Avg. loss: 0.394737\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580452, T: 112500, Avg. loss: 0.385561\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.660824, T: 150000, Avg. loss: 0.382161\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.717218, T: 187500, Avg. loss: 0.380474\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.761816, T: 225000, Avg. loss: 0.379481\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.793932, T: 262500, Avg. loss: 0.379096\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.820446, T: 300000, Avg. loss: 0.378826\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.840093, T: 337500, Avg. loss: 0.378604\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.850329, T: 375000, Avg. loss: 0.378615\n",
      "Total training time: 0.10 seconds.\n",
      "Convergence after 10 epochs took 0.10 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.42328902,  0.18380407, -0.14437354,  0.34064016, -0.21316099,\n",
       "          0.56702655, -0.44910569, -0.09094413,  0.21219292,  0.17750247,\n",
       "          0.19931732, -0.00506998, -0.07781235,  0.33343476,  0.0320374 ]]),\n",
       " (1, 15),\n",
       " array([-0.85032916]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "X.shape, y.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WaVxhGpSvnj",
    "outputId": "1e67badc-96e7-4633-eb72-1d4c24aaa295"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Su9e8fRLSvno"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcz5_UqCSvnq"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOBvEchCSvnr"
   },
   "source": [
    "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xbn61rrXSvnt"
   },
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14bA5yR3Svnv"
   },
   "source": [
    "- Load the datasets(train and test) into the respective arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7183hFBSvnv"
   },
   "source": [
    "- Initialize the weight_vector and intercept term randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdLeFU0USvnx"
   },
   "source": [
    "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEVtAlO1Svny"
   },
   "source": [
    "- for each epoch:\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
    "        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n",
    "        $b^{(t+1)} ← (1 − \\frac{αλ}{N} )b^{(t)} + α(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ \n",
    "        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qmRH4UpSvny"
   },
   "source": [
    "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbZf9p5gSvn1"
   },
   "source": [
    "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fpz8X5DMSvn2"
   },
   "outputs": [],
   "source": [
    "w = np.zeros_like(X_train[0])\n",
    "b = 0\n",
    "eta0  = 0.0001\n",
    "alpha = 0.0001\n",
    "N = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6Y5kVscSvn5"
   },
   "outputs": [],
   "source": [
    "# write your code to implement SGD as per the above instructions\n",
    "# please choose the number of iternations on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yy8jWaa7Svn_",
    "outputId": "a5bdc6de-084e-4c0d-d905-3529d0dd268a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.42328902, -0.18380407,  0.14437354, -0.34064016,  0.21316099,\n",
       "         -0.56702655,  0.44910569,  0.09094413, -0.21219292, -0.17750247,\n",
       "         -0.19931732,  0.00506998,  0.07781235, -0.33343476, -0.0320374 ]]),\n",
       " array([0.85032916]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w, X, b):\n",
    "    return 1/(1+exp(-(dot(x,w)+b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48gx6wQKSvoE",
    "outputId": "73838465-1f8e-4697-fe22-c49a816e1207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6978933333333335\n",
      "1.6986400000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def sigmoid(w, X, b):\n",
    "    return 1/(1+math.exp(-(np.dot(X,w)+b)))\n",
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        if sigmoid(w,X[i], b) >= 0.5:\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic Regression using SGD.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
